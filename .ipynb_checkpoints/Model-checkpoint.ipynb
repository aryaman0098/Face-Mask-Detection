{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample image\n",
    "image = load_img(\"./dataset/with_mask/0-with-mask.jpg\", target_size = (120, 120))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.ndarray((1694, 150, 150, 3), dtype = \"float32\")\n",
    "y = []\n",
    "c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the images and corresponding labels\n",
    "path  = path = pathlib.Path(\"./dataset/with_mask\")\n",
    "for i in path.iterdir():\n",
    "    image = load_img(str(i), target_size = (150, 150))\n",
    "    image = np.asarray(image)\n",
    "    x_train[c] = image\n",
    "    c = c + 1\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the images and corresponding labels\n",
    "path  = path = pathlib.Path(\"./dataset/without_mask\")\n",
    "for i in path.iterdir():\n",
    "    image = load_img(str(i), target_size = (150, 150)) \n",
    "    image = np.asarray(image)\n",
    "    x_train[c] = image\n",
    "    c = c + 1\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "x_train.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(x_train, y, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample\n",
    "plt.imshow(X[1].squeeze(), cmap = \"gray\"), y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing into train, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.2, random_state = 7)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_validation, y_validation, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_validation.shape, X_test.shape, y_train.shape, y_validation.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converitng the labels into categorical form\n",
    "import keras\n",
    "number_cat = 2\n",
    "y_train = keras.utils.to_categorical(y_train, number_cat)\n",
    "y_validation = keras.utils.to_categorical(y_validation, number_cat)\n",
    "y_test = keras.utils.to_categorical(y_test, number_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_validation.shape, X_test.shape, y_train.shape, y_validation.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample\n",
    "plt.imshow(X_train[1331].squeeze(), cmap = \"gray\"), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (150, 150, 3)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 256, activation = \"relu\"))\n",
    "\n",
    "model.add(Dense(units = 512, activation = \"relu\"))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(units = 1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units = 2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer= keras.optimizers.Adam(learning_rate=0.001), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 35, batch_size = 32 , validation_data = (X_validation, y_validation), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], \"r\", label = \"training loss\")\n",
    "plt.plot(history.history['val_loss'], \"b\", label = \"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], \"r\", label = \"training loss\")\n",
    "plt.plot(history.history['val_accuracy'], \"b\", label = \"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(\"test accuracy: {}\" .format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = model.predict_classes(X_test)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted_class)\n",
    "cm\n",
    "plt.figure(figsize  = (15, 15))\n",
    "sns.heatmap(cm, annot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
