{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample image\n",
    "image = load_img(\"./dataset/with_mask/0-with-mask.jpg\", target_size = (120, 120))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.ndarray((1394, 150, 150, 3), dtype = \"float32\")\n",
    "y = []\n",
    "c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the images and corresponding labels\n",
    "path  = path = pathlib.Path(\"./dataset/with_mask\")\n",
    "for i in path.iterdir():\n",
    "    image = load_img(str(i), target_size = (150, 150))\n",
    "    image = np.asarray(image)\n",
    "    x_train[c] = image\n",
    "    c = c + 1\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the images and corresponding labels\n",
    "path  = path = pathlib.Path(\"./dataset/without_mask\")\n",
    "for i in path.iterdir():\n",
    "    image = load_img(str(i), target_size = (150, 150)) \n",
    "    image = np.asarray(image)\n",
    "    x_train[c] = image\n",
    "    c = c + 1\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y)\n",
    "x_train.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data for better performance\n",
    "X , y = shuffle(x_train, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample data\n",
    "plt.imshow(X[1].squeeze(), cmap = \"gray\"), y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the labels into a categorical form i.e for \"MASK\" : 1 and \"NO MASK\" : 0\n",
    "import keras\n",
    "number_cat = 2\n",
    "y_train = keras.utils.to_categorical(y_train, number_cat)\n",
    "y_test = keras.utils.to_categorical(y_test, number_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0].squeeze(), cmap = \"gray\"), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN architecture 1 for classifying the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units = 128, activation = \"relu\"))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(units = 2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.rmsprop(lr = 0.001), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "history = model.fit(X_train, y_train, epochs = 15, batch_size = 32 , validation_data = (X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], \"r\", label = \"training loss\")\n",
    "plt.plot(history.history['val_loss'], \"b\", label = \"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], \"r\", label = \"training loss\")\n",
    "plt.plot(history.history['val_accuracy'], \"b\", label = \"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size = 0.1, random_state = 0)#Reshuffling the images again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cat = 2\n",
    "y_train1 = keras.utils.to_categorical(y_train1, number_cat)\n",
    "y_test1 = keras.utils.to_categorical(y_test1, number_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN architecture 2 for classifying the images (it is simialar to the first model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = \"relu\", input_shape = (150, 150, 3)))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model1.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model1.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model1.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model1.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(units = 256, activation = \"relu\"))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Dense(units = 128, activation = \"relu\"))\n",
    "model1.add(Dropout(0.33))\n",
    "\n",
    "model1.add(Dense(units = 2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = \"categorical_crossentropy\", optimizer = keras.optimizers.rmsprop(lr = 0.001), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "history1 = model1.fit(X_train1, y_train1, epochs = 15, batch_size = 32 , validation_data = (X_test1, y_test1), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['loss'], \"r\", label = \"training loss\")\n",
    "plt.plot(history1.history['val_loss'], \"b\", label = \"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['accuracy'], \"r\", label = \"training loss\")\n",
    "plt.plot(history1.history['val_accuracy'], \"b\", label = \"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"Model2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
